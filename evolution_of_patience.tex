\documentclass[titlepage, hidelinks, 12pt]{article}


%for custom page numbering:
\usepackage{fancyhdr}

\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{palatino}
\usepackage{tikz}
\usepackage{chngcntr}
\counterwithin{figure}{section}
%\usepackage{breqn} % useful for breaking equations across multiple lines automatically. Breaks everything.


\usepackage{setspace}
%\usepackage{indentfirst} %tex default is no indent on first paragraph after heading
\usepackage{url}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{float}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{environ, enumerate}
%\usepackage{mathbbol}
%\DeclareSymbolFontAlphabet{\amsmathbb}{AMSb}
\graphicspath{ {images/} }
\providecommand{\keywords}[1]{\textbf{\textit{Keywords---}} #1} 
\usepackage[format=plain,
            labelfont={bf, it},
            textfont=it]{caption}

\usepackage{lineno}

\usepackage{epigraph}

% \epigraphsize{\small}% Default
\setlength\epigraphwidth{8cm}
\setlength\epigraphrule{0pt}

\usepackage{etoolbox}

\makeatletter
\patchcmd{\epigraph}{\@epitext{#1}}{\itshape\@epitext{#1}}{}{}
\makeatother

% Align and Lineno do not play well together. This should fix it:

\newcommand*\linenomathpatch[1]{%
  \cspreto{#1}{\linenomath}%
  \cspreto{#1*}{\linenomath}%
  \csappto{end#1}{\endlinenomath}%
  \csappto{end#1*}{\endlinenomath}%
}

\linenomathpatch{equation}
\linenomathpatch{gather}
\linenomathpatch{multline}
\linenomathpatch{align}
\linenomathpatch{alignat}
\linenomathpatch{flalign}



%%%%%%%%%
% indentation
%%%%%%%%%

\setlength\parindent{24pt}

\setlength{\voffset}{-1cm}
\setlength{\textwidth}{17cm}
\addtolength{\textheight}{2cm}
\setlength{\footskip}{1cm}
\addtolength{\oddsidemargin}{-2cm}
\addtolength{\evensidemargin}{-2cm}

\widowpenalty10000
\clubpenalty10000

%%%%%%%%%
% page numbering and logo
%%%%%%%%%

\pagestyle{fancy}

\fancyhead[L, C]{}
\fancyhead[R]{\includegraphics[scale=.35]{sb_logo_black.png}}
\fancyfoot[L]{}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


%Def, Lemma, Theorem, Corollary environment
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{question}[theorem]{Question}
%\newtheorem*{proof}{Proof}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

%New commands
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\betahat}{\hat{\beta}}

\newcommand{\varSS}{\frac{\partial \lambda}{ \partial b_{a}}}
\newcommand{\varLL}{\frac{\partial \lambda}{ \partial b_{a+1}}}
\newcommand{\LH}{\mathcal{LH}}




%New math operators
\DeclareMathOperator{\ringchar}{char}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator*{\argmax}{argmax} \DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\MRS}{MRS}
\DeclareMathOperator{\smallersooner}{SS}
\DeclareMathOperator{\largerlater}{LL}
\DeclareMathOperator{\ES}{ES}
%\DeclareMathOperator{\exp}{exp}
\DeclareMathOperator{\hyp}{hyp}
\renewcommand\d[1]{\:\textrm{d}#1}
\newcommand*\diff{\mathop{\!\mathrm{d}}}

\doublespacing
\begin{document}
\begin{singlespace}
\begin{titlepage}
   \begin{center}
       \vspace*{1cm}
\Huge
       \textbf{The Adaptive Dynamics of Patience} \\
\Large
       \vspace{0.5cm}
      
            
       \vspace{4.1cm}
       \includegraphics[scale = 1.4]{sb_logo_black.png} \\
       \vspace*{\fill}
       \textbf{Eric, Christoph, and Jaye } 

            
       Department of Mathematics\\
       University of British Columbia
            
   \end{center}
\end{titlepage}


%%HERE IS A TEST CHANGE FOR BRANCH PURPOSES


\begin{abstract}
    Time preferences describe an individual's willingness to wait for a delayed reward in the presence of a smaller/sooner alternative. 
    Much debate has been had between the validity of the exponential and hyperbolic discounting models of time preferences on theoretical 
    and empirical grounds. 
We put forward an evolutionary model which allows adaptive pressures to mould time preferences. 
We consider a trait substitution sequence, which assumes a population with uniform time preferences subject to small, random mutations which
either fixate or are eliminated. We use
standard results from adaptive dynamics to explicitly compute an evolutionarily stable set of time preferences to which our trait substitution sequence
converges. Our results imply that individual survival probability and ambient population growth determine risk and opportunity cost, respectively.
    \bigskip

    \begin{keywords}
        Time Preferences, Adaptive Dynamics, Exponential Discounting, Life History, Preference Reversals. 
    \end{keywords}

\end{abstract}

%\newpage

%\tableofcontents

\newpage

%\section*{Acknowledgements}
%\addcontentsline{toc}{section}{Acknowledgement}
%\newpage
%\input{texfiles/outline}
%\newpage
\end{singlespace}

\epigraph{Time is the most valuable thing a man can spend.}{---Theophrastus}
\linenumbers
\section{Introduction}

Individuals often make decisions with delayed consequences. For instance, consider deciding between chocolate and fruit salad
for desert. While chocolate offers immediate satisfaction, fruit salad provides more health benefits which are felt later in time. 
Dilemmas between small, more immediate rewards and larger, more delayed rewards are typical. 
At the personal level, examples include decisions involving diet, exercise, or the management of addictions. At a more global scale, 
environmental policy (to reduce output in the present to preserve resources for future use) also involves a temporal dilemma between
a smaller/sooner and larger/later benefit. 

An individual's \textit{time preferences} describe their decision facing any potential temporal dilemma. Time preferences are
quantitatively described using a discounting function $\Delta$, encoding how quickly a delayed reward loses its value. Suppose a specific individual
values the satisfaction of chocolate at $1$, whereas they value the health benefits provided by fruit salad at $1.5$. 
If the health benefits of fruit salad were available immediately, the individual under consideration would prefer fruit salad. However, 
since health benefits come after a delay (which we normalize to 1, for simplicity), whether the individual prefers chocolate or fruit 
is determined by their time preferences.
Mathematically, fruit salad is preferred if and only if
\begin{align}
    \text{Benefit of Chocolate} &< (\text{Discount Factor}) \cdot (\text{Benefit of Fruit}) \\
    \iff 1 &< \Delta(1) \cdot 1.5
    \label{eqn:choco_or_fruit}
\end{align}
Many studies have considered why (in theory) and how (in practice) individuals value time \cite{mazur85, ainslie75, green81, green04}. 
Correspondingly, specific discounting functions can be derived from mathematical models or instead configured to match experimental data. 


Consider a simple model of time preferences.
Assume that delayed rewards lose a constant fraction of their value for every unit-time delay. This assumption 
results in an exponential discounting function, of the form
\begin{equation}
    \Delta_{\exp}(t) = e^{-r t}.
\end{equation}
Here, $r>0$ is a parameter indicating how quickly a reward loses its value. 
The exponential discounting model is popular among economists in particular
for its straightforward assumptions and ease of use \cite{sozou98}. 
In particular, the model 
agrees with financial models in which loans accrue compound interest at a specified rate $r>0$. An initial loan of $P$ at compound interest
rate $r$ appreciates (after $t$ units of time) to 
\begin{equation}
    P(1 + r)^{t} = Pe^{\log(1+r) t} = Pe^{\tilde{r}t},
    \label{eqn:compound_interest}
\end{equation}
which grows exponentially in time $t$. 
Appreciation is the reciprocal of discounting, and either may be used depending on which more naturally suits our application. 


Experimental results find that observed discounting behaviour is better explained
by a hyperbolic, rather than exponential, discounting function \cite{maia09, green04, doyle12}. A hyperbolic discounting function takes
the form:
\begin{equation}
    \Delta_{\hyp}(t) = \frac{1}{1+ht},
\end{equation}
where $h>0$ is a parameter analogous to $r$ in the exponential discounting model. The hyperbolic discounting model is considerably less
popular than the exponential model, in part due to its lack of theoretical foundations. One derivation of the hyperbolic discounting model relies
on additive, \textit{simple interest} computations, which in financial modelling is considered irrational \cite{rachlin06}. An initial loan
of $P$ at simple interest rate $h$ appreciates after $t$ units of time to
\begin{equation}
    P + hP + hP + \cdots + hP = P(1 + ht)
    \label{eqn:simple_interest}
\end{equation}
which grows linearly in time $t$. 

\begin{figure}[H]
    \centering
    \includegraphics{discounting_appreciation.png}
    \caption[Example discounting and corresponding appreciation schedules.]{Discounting versus appreciation in delayed rewards. 
        (a): the discounted value of a reward of magnitude $1$ plotted as a function of delay $t$.  
        (b): the same time preferences represented with appreciation, which is the reciprocal of discounting. An immediate reward of size $1$ is
        of the same perceived value as a reward of size $1/\Delta(t)$ received after delay $t$. 
        Hyperbolic and exponential time preferences are more easily distinguished by appreciation, rather than discounting, plots.
        Exponential discounters exhibit exponential
        growth in appreciation, whereas hyperbolic discounting is consistent with linear growth.}
\end{figure}



Experimentalists further find evidence of behaviour not compatible with the exponential discounting model \cite{read98}. 
When deciding between a snack of chocolate and fruit, varying the delay before consumption can change preferences;
some study participants prefer a chocolate bar
when they will consume immediately, but prefer fruit salad if they are to snack after a week. To switch from impulsiveness (chocolate) to patience
(fruit) as
both alternatives become further removed is called a preference reversal. A preference reversal of this nature is shown in Figure 
\ref{fig:discountedValueHyperbolic}.
Notably, exponential discounting is the only model of time preferences which does not predict preference reversals
\cite{strotz55}. 




\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.7]{discountedValueHyperbolic.png}
    \caption[Graphical depiction of a preference reversal.]{Preference reversals are predicted by hyperbolic discounting. Suppose an individual
        chooses between a desert of either chocolate
        or fruit salad, to be consumed after some common delay $t$. As in the text,
        chocolate has a value of $1$ and fruit has a value of $1.5$ (received after an additional delay of one unit of time). 
        The figure shows the discounted value
        of each alternative by a hyperbolic discounter ($h = 1$): chocolate is preferred if and only if the common delay $t < 1$. }
    \label{fig:discountedValueHyperbolic}
\end{figure}


We propose to use techniques from evolutionary modeling to resolve the discrepency between the theory and the reality of time preferences.
Of note, all discounting examples until present have involved humans; this need not be the case. Decisions involving patience are made by both
human and non-human animals \cite{fawcett12}. While researchers, accountants, and financial engineers may quantify time preferences using
discounting functions, most smaller/sooner or larger/later decisions are guided by intuition rather than mathematics. The intuition determining
time preferences has been called the \textit{adaptive unconscious}, which is the collection of mental processes we use when making 
decisions without conscious and deliberate consideration \cite{wegner02}. The adaptive unconscious is adaptive in that it favours behaviour
aiding survival and reproductive success. Those offspring born with better instincts are more likely to survive/reproduce, so that in the long
run, those with adaptive instincts dominate. Our core assumption throughout this article is that time preferences are determined by the adaptive
unconscious. We perform evolutionary modeling to determine instinctive time preferences described by an adaptive discounting function, which
we denote $\Delta^*$. 

Our research is not the first to focus on time preferences from an evolutionary angle. Previous approaches explicitly consider both
risk and opportunity cost to compute the relative value of immediate and delayed rewards, prescribing adaptive behaviour as a function of
each \cite{sozou98, fawcett12}. Risk refers to the possibility that a delayed reward may not be realized (due, for instance, to death
of the recipient), whereas opportunity cost 
references the principle that
time is valuable: delayed rewards are intrinsically worth less than immediate rewards even in the absence of risk.
If risk is constant and known, adaptive time preferences are modeled by exponential discounting; however, if risk is constant but drawn
from a known distribution, hyperbolic discounting may be adaptive \cite{sozou98}. If risk is constant, explicitly accounting for opportunity
cost yields various models predicting preference reversals \cite{fawcett12}.  

A consistent approach to the application of evolutionary modeling to time preferences is to assume that delayed rewards 
translate directly to fitness outcomes. In this article, we add an intermediate step, considering rewards in units of future offspring which we 
subsequently convert to a fitness measurement. Consequently, the relative value of delayed rewards is not determined by subjective and debatable
evaluations of risk or opportunity cost, but instead mechanistically determined by the choice of fitness measurement. 
The demographic factors survival and ambient population growth determine risk and opportunity cost, respectively. 
Our contribution is to put forward a model making less assumptions and which reinforces the core hypotheses in previous research. We apply
our model to a highly general demographic setting in which we derive time preferences corresponding to any risk and reward profile. Finally,
we apply our approach to better understand preference reversals and reconcile the theory and empirics of discounting. 




\section{Life Histories and Reproductive Success}

Consider a discrete time setup with a large population
in which each agent's age is indexed by $a\in\left\{ 0, 1, \ldots, A \right\}$. That time is discrete is
not a limiting assumption, since in practice we may take units of time small enough so as to be essentially continuous. Further, 
the imposition of a maximal age class $A$ is reasonable since we may take $A$ large enough that death is guaranteed after
age $A$. Suppose every individual in the population is subject to the same survival and fecundity
schedules, $\vec{s} = (s_0, s_1, \ldots, s_{A-1}, s_A = 0)$, and $\vec{b} = (b_0, b_1, \ldots, b_A)$. Here, 
$s_a$ is the probability of surviving from age $a$ to $a+1$, and $b_a$ is the expected
number of offspring produced conditional on reaching age $a$. 
The survival/reproduction pair of schedules $(\vec{s}, \vec{b})$
is called the population's life history $\LH_0$. 

We use this population to study the evolution of time preferences by providing agents with reproductive dilemmas: a choice
between some offspring early in life and more offspring later. Agents' time preferences determine their reproductive schedule
(in addition to baseline life history $\LH_0$). We assume 
time preferences are subject to small mutations and study their evolutionary trajectory. Our analysis relies on 
standard fitness measures from evolutionary ecology: lifetime progeny $R_0$ and monomorphic population growth rate $\lambda$ 
\cite{stearns92}.
 

Lifetime reproductive output is computed as
\begin{equation}
    R_0 = \sum\limits_{a = 0}^A \prod\limits_{k = 0}^{a-1} s_k b_a.
    \label{eqn:output}
\end{equation}
This is the sum of the expected number of offspring produced at each age $a= 0, 1, \ldots, A$. 
Population growth (also called the Lyapunov exponent) $\lambda$
appears in the discrete-time Euler-Lotka equation,
\begin{equation}
    \lambda^{A+1} - \sum\limits_{a = 0}^A \lambda^{A-a} \prod\limits_{k = 0}^{a-1}s_k b_k= 0.
    \label{eqn:euler-lotka}
\end{equation}


Whereas the expression for $R_0$ is easily computed, the Euler-Lotka equation
is a polynomial in $\lambda$ of degree $A+1$, and so has up to $A+1$ distinct solutions. The largest of these solutions is the growth
rate of a monomorphic population, the Lyapunov exponent.
The Euler-Lotka equation is derived from the Leslie matrix describing population dynamics with life history $\LH_0$ \cite{stearns92}.
While it is not possible to compute analytically, the Lyapunov exponent is implicitly a function of life history data:
\begin{equation}
    \lambda = \lambda(\LH_0) = \lambda(s_0, s_1, \ldots, s_{A-1}, b_0, b_1, \ldots, b_{A}).
    \label{eqn:lambda_function}
\end{equation}
In practice, the Lyapunov exponent is computed numerically, and in each expression, the empty product evaluates to $1$. 
In the long run, a population with fixed life history will converge to a stable age distribution and
thus grow (or decay) 
exponentially at a constant rate $\lambda$ per unit time. If $\lambda = 1$, then the population remains at a fixed size indefinitely.

We use population growth $\lambda$ as our measure of reproductive success. The assumption that populations grow exponentially is limiting: if
ever $\lambda > 1$,  we implicitly assume that resources are in inexhaustible supply 
and do not constrain growth. A sustainable population is one that is of constant size, which has
$\lambda \approx 1$. The question is now: What selective pressures does $\lambda$ 
exert over time preferences?


\section{Reproductive Dilemmas}
Recall that time preferences are defined to be an individual's decision facing any dilemma between a smaller/sooner reward
and a larger/later alternative. By presenting agents with such dilemmas and allowing an evolutionary process to determine which
time preferences are adopted and which go extinct, we may determine adaptive time preferences. 

In our model, we present each agent with a stochastically determined
smaller/sooner versus larger/later fecundity dilemma.  As motivation, consider
a randomly varying environment in which resource fluctuations result in the option to
increase reproduction at various points over the life history. Note that these fecundity increases are in addition to a baseline life history
$\LH_0$ common to all agents.  
Fix $\varepsilon > 0$ small.  
Individuals decide between:
\begin{enumerate}
    \item $\smallersooner:$ increase fecundity at age $a$ to $b_a\uparrow b_{a} + \varepsilon$, and
    \item $\largerlater:$ increase $b_{a+1}\uparrow b_{a+1} + F\cdot \varepsilon$.
\end{enumerate}

We use $\varepsilon > 0$ (small) as our unit of fecundity dilemma, assuming environmental stochasticity results in relatively minor changes to 
fecundity. 
Denote each dilemma by the pair $(a, F)$, where $a$ is the age at which the dilemma is faced,
and $F$ is the ratio of $\largerlater$ to $\smallersooner$. 
Remark that we assume dilemmas are between age $a$ and $a+1$ rather than an arbitrary delay $a+t$. This restriction simplifies our analysis
while still allowing for a full understanding of evolved time preferences, since knowing preferences between $a$ and $a+1$ as well as between
$a+1$ and $a+2$, we infer preferences between $a$ and $a+2$. 

\begin{figure}[H]
    \centering
    \includegraphics{evolutionary_dilemma.png}
    \caption[Baseline life history and reproductive dilemma example.]{A baseline life history $\vec{s}, \vec{b}$ can be visualized as a bar plot. The bar at $a$ is the expected number of offspring at
        age $a$, given by
    $\prod_{k = 0}^{a-1} s_k b_a$. Reproductive dilemmas are additions to fecundity. Illustrated is the dilemma $(2, 3)$, with
$\varepsilon = 0.01$. That is, an agent faces a choice between an additional $0.01$ offspring at age $2$ and an additional $0.03$ offspring
at age $3$.} 
\end{figure}

Individuals in our model have time preferences which indicate their preferred choice between $\smallersooner$ and $\largerlater$ facing any
dilemma. 
Consider a dilemma $(a, F)$. The switching point $x_a$ is the unique value satisfying that $\smallersooner$ is preferred
if and only if $F < x_a$. 
A patience threshold is a collection of switching points $(x_0, \ldots, x_{A-1})$.
Since a patience threshold indicates preferences facing any dilemma $(a, F)$, time preferences may be uniquely 
specified by either a patience threshold or a discounting function. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{switching_point_pref_rev.png}
    \caption[Patience threshold and alternative perspective on preference reversals.]{Patience thresholds are mathematically convenient and provide a straightforward visual representation of time preferences. 
        Every point in $(a, F)$ space
    represents a dilemma at age $a$ with reward ratio $\largerlater : \smallersooner = F$. 
    Those points above the patience threshold correspond to dilemmas at which the $\largerlater$ alternative
is preferred. Those points below the threshold are when $\smallersooner$ is preferred. The patience threshold also allows
illustrates preference reversals. Consider the family of dilemmas $(a, 1.5)$, with age at dilemma $a$ variable (dotted black line). If the dilemma comes 
before age $a = 1$, the agent 
prefers $\smallersooner$. However, if the dilemma comes later in life, then $\largerlater$ is preferred. More generally, a
downward sloping patience threshold indicates preference reversals from $\smallersooner\to\largerlater$, and an upward sloping threshold
indicates the reverse. A horizontal patience threshold is consistent with exponential discounting, and indicates no preference reversals.
}
\end{figure}

By way of summary, our model includes a large (or infinite) population sharing the same baseline life history $\LH_0 = (\vec{s}, \vec{b}).$ 
Each agent faces a stochastically determined dilemma, denoted $(a, F)$, between a smaller/sooner and a larger/later fecundity reward. 
Time preferences are given by a patience threshold $(x_0, x_1, \ldots, x_{A-1})$. 
An individual's time preferences determine their reproductive success; by using the Lyapunov exponent $\lambda$ to measure reproductive 
success, we are using the difference in population growth rate between residents and mutants to compute the evolutionary dynamics of time
preferences and patience. 


\section{Adaptive Dynamics of Patience}
Adaptive dynamics is a framework for mathematically describing the trajectory of a continuosly varying trait when subject to evolutionary pressures. 
Adaptive dynamics makes two key assumptions. We assume that mutations (i) are small, and (ii) occur infrequently.
Under these assumptions, a mutant either goes extinct or replaces the resident population before any more mutations occur \cite{doebeli05}.
A value to which a trait converges is called convergent stable. A value to which a trait remains if already there is called evolutionarily stable.
Neither form of stability implies the other. For instance, a trait value which is convergent stable and not evolutionarily stable is called an
evolutionary branching point. A major contribution of adaptive dynamics is the explanation of sympatric speciation, the 
evolution of two different species in the same environment \cite{doebeli11}. 

More technincally, suppose a continuously varying trait is subject to evolutionary pressures. \textit{Invasion fitness} is the relative
success of a rare mutant with trait value $y$ invading into a monomorphic population with trait value $x$, $\varphi(y, x)$. If invasion
fitness is positive, $\varphi(y, x) > 0$, then a rare mutant fixates. Our framework lends itself well to analysis by differentiation. 
Increasing the trait value slightly is either beneficial, in which case the mutation fixates, or it is not beneficial, in which
case the mutation vanishes. Adaptive dynamics describes the trajectory of the trait value $x$. 
The \textit{selection gradient} is the function 
\begin{equation}
    D(x) = \left.\frac{\partial }{\partial y} \right\vert_{y = x}\varphi(y, x).
    \label{eqn:selection_gradient}
\end{equation}
If trait value $x$ is such that $D(x) > 0$, increasing the trait value is adaptive. If $x^*$ is such that $D(x^*) = 0$, then $x^*$ is a
singular value. If $D(x^*) = 0$ and $D'(x^*) < 0$, 
then $x^*$ is convergent stable: the trait value will converge to $x^*$. To determine if the trait value will remain at $x^*$, compute
\begin{equation}
    \ES(x) = \left.\frac{\partial^2 }{\partial y^2} \right\vert_{y = x}\varphi(y, x).
    \label{eqn:evolutionary_stability}
\end{equation}
If $\ES(x^*) < 0$, then trait value $x^*$ is evolutionarily stable. The trait converges to and remains at $x^*$. On the other hand, if
$\ES(x^*) > 0$, then $x^*$ is an evolutionary branching point: after converging to $x^*$, two distinct populations diverge from value $x^*$, one
with trait values above and the other below $x^*$.  We here apply adaptive dynamics to the evolution of time preferences. 

Suppose a population has baseline life history $\LH_0$ and begins with all individuals having the same time preferences,
encoded as a patience threshold $(x_0, x_1, \ldots, x_{A-1})$. We compute the adaptive dynamics of each switching point
$x_a$ independently. We first consider a mutant with switching point $y_a > x_a$ for age at dilemma $a$ fixed. 
The mutant under consideration is slightly less patient than the resident population. Residents and mutants obtain identical outcomes except for dilemmas
at age $a$ with ratio $F$ such that $x_a < F < y_a$, meaning residents choose $\largerlater$ and mutants choose $\smallersooner$. 
To determine if the mutant with trait value $y_a$ is benefited, we analytically compute reproductive success via a first order Taylor approximation:
\begin{align}
    \lambda(\LH_0 + \smallersooner) &\approx \lambda(\LH_0) + \varepsilon \cdot \varSS \\
    \lambda(\LH_0 + \largerlater) &\approx \lambda(\LH_0) + F\varepsilon \cdot \varLL.
\end{align}
Recall from equation (\ref{eqn:lambda_function}) that the Lyapunov exponent is implicitly a function of the fecundity terms $b_a$. 
From the Taylor approximation we identify the payoff from choosing each alternative, 
$\pi_{\smallersooner}$ and $\pi_{\largerlater}(F)$. Remark that the larger/later payout
varies as a function of $F$, whereas the smaller/sooner payout is constant. We have: 
\begin{align}
    \pi_{\smallersooner} &= \varepsilon\cdot \varSS \label{eqn:varss} \\ 
    \pi_{\largerlater}(F) &= F\varepsilon\cdot \varLL. \label{eqn:varll}
\end{align}

Invasion fitness describes the relative success of a rare mutant, and is the difference in reproductive success between
a mutant and residents.  We assume dilemmas
vary stochastically, so invasion fitness is the \textit{average} difference in success. Suppose the larger/later value $F$ is distributed with probability
density function $g(F)$. 
Denote by $\varphi_a(y_a, x_a)$ the invasion fitness of a mutant with switching point
$y_a$ into a resident population with switching point $x_a$.  
Recall that when $x_a < F < y_a$, residents choose the larger/later option and mutants prefer the smaller/sooner alternative, whereas
outside of this interval outcomes are identical. Invasion fitness is then the average difference $\pi_{\smallersooner} - \pi_{\largerlater}(F)$
over all dilemmas $(a, F)$, for $a$ fixed. 
Mathematically, therefore, invasion fitness is given by 
\begin{align}
    \varphi_a(y_a, x_a) &= \mathbb{E}\left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \ | \ x_a < F < y_a\right] \\
    &= \int_{x_a}^{y_a} \left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \right]g(F) \d F. 
\end{align}
Remark that the expression for invasion fitness
$\varphi_a$ is the same whether $x_a < y_a$ or $y_a < x_a$, and is $0$ when $x_a = y_a$. 
Since we assume dilemmas are distributed randomly, we compute the expected value as a weighted integral according to the distribution of $F$ over
the interval on which the payouts differ. 

From invasion fitness $\varphi_a(y_a, x_a)$, we compute the selection gradient $D(x_a)$ to determine which switching points
are singular strategies.  
Recall that increasing the switching point $x_a$ is adaptive if and only if $D(x_a) > 0$. We compute: 
\begin{align}
    D(x_a) &= \left.\frac{\partial }{\partial y_a} \right\vert_{y_a = x_a}\varphi_a(y_a, x_a)  \\
    &=\left.\frac{\partial }{\partial y_a} \right\vert_{y_a = x_a}  \int_{x_a}^{y_a} \left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \right]g(F) \d F\\
        &=\left[ \pi_{\smallersooner} - \pi_{\largerlater}(x_a)   \right]g(x_a) 
\end{align}
We verify that $D(x_a^*) = 0$ is solved whenever the payout from choosing smaller/sooner equals that from choosing larger/later,
$\pi_{\smallersooner} = \pi_{\largerlater}(x_a^*)$. Intuitively, this result is reasonable: the singular switching point 
is the one at which the payout from smaller/sooner is the same as that from larger/later. 
We compute from equations (\ref{eqn:varss}) and (\ref{eqn:varll}) that
$x_a^* =  \varSS/\varLL$. 

We can further show that $x_a^*$ 
is both convergent stable and evolutionarily stable. Convergent stability follows from showing that $D'(x_a^*) < 0$, whereas evolutionary
stability follows from showing that $\frac{\partial^2 \varphi_a}{\partial y_a^2}(x_a^*, x_a^*)< 0$. In our case, the conditions are equivalent,
so we compute:
\begin{align}
    \frac{\partial^2 \varphi_a}{\partial y_a^2}(y_a, x_a) &=\frac{\partial}{\partial y_a}\left[\varSS \cdot \varepsilon  - \varLL \cdot y_a\varepsilon \right] g(y_a)\\
    &= \left[ -\varepsilon \varLL \right]\cdot g(y_a) + \left[ \varepsilon \varSS - y_a \right]
\end{align}
By evaluating at $(y_a, x_a) = (x_a^*, x_a^*)$, we determine the convergent and evolutionary stability of $x_a^*$. 
\begin{align}
    \frac{\partial^2 \varphi_a}{\partial y^2}(x_a^*, x_a^*) &= -\varepsilon \varLL g(x_a^*) + \left[ \varepsilon \varSS - \varepsilon \frac{\varSS}{\varLL}
    \varLL\right]g'(x_a^*) \\
    &= -\varepsilon \varLL g(x_a^*) + \left[0  \right]\cdot g'(x_a^*)\\
    &= -\varepsilon\varLL g(x_a^*) < 0 \label{eqn:negative}
\end{align}
The quantity in line (\ref{eqn:negative}) is negative. By assumption, $\varepsilon > 0$. Since $g$ is a probability density function, it is also
positive. Finally, since reproductive success $\lambda$ increases with fecundity, the derivative is also positive, and so the expression is
negative. 
We conclude that the switching point will converge to $x_a^*$, and once there, it will not deviate: the switching point $x_a^*$ is both
convergent and evolutionarily stable. 

Remark that the switching point $x_a^* =  \varSS/\varLL$ has been computed specifically for dilemmas at age $a$. We therefore now extend to
the evolutionarily stable patience threshold $(x_0^*, x_1^*, \ldots, x_{A-1}^*)$. 
We may translate with ease between discounting functions and patience thresholds. Given any patience threshold $(x_0, x_1, \ldots)$, the corresponding
discounting schedule is given by 
\begin{equation}
    \Delta(t) = \left( \prod\limits_{k = 0}^{t - 1} x_k \right)^{-1}. \label{eqn:disc_from_thresh}
\end{equation}
Consequently, the evolutionarily stable discounting function (corresponding to our derived patience threshold) is
\begin{equation}
    \Delta^*(a) = \varSS/\frac{\partial \lambda}{\partial b_0}. 
    \label{eqn:stable_discounting}
\end{equation}
Between equations (\ref{eqn:disc_from_thresh}) and (\ref{eqn:stable_discounting}), the delay variable changes from $t$ to $a$. 
We do so to highlight an important difference between the classical theory of time preferences and our approach. 
Classical discounting functions are age agnostic: delayed rewards are discounted to present value. In our evolutionarily stable discounting
function $\Delta^*(a)$, however, age matters. Rather than offering a reward today or more tomorrow, we offer a reward at age $a$ or a larger
reward at age $a+1$. To compare delayed rewards against a common benchmark, delayed rewards are translated to discounted value at
age $0$, the initial age class. 

The Euler-Lotka equation can be leveraged to compute an expression for the evolutionarily stable switching points. By using
implicit differentiation, we compute
\begin{equation}
    \frac{\partial \lambda}{\partial b_a} = K\cdot \lambda^{-a} \prod\limits_{k = 0}^{a-1}s_k,
\end{equation}
where $K>0$ is an expression independent of $a$. We can now compute the evolutionarily stable switching point 
\begin{equation}
    x_a^* = \frac{\varSS}{\varLL} = \frac{K\cdot \lambda^{-a} \prod\limits_{k = 0}^{a-1}s_k}{K\cdot \lambda^{-a-1} \prod\limits_{k = 0}^{a}s_k} = \frac{\lambda}{s_a}.
\end{equation}
We further compute the adaptive discounting function
\begin{equation}
    \Delta^*(a) = \lambda^{-a}\prod\limits_{k = 0}^{a-1} s_k.
\end{equation}



\section{Interpretation and Discussion}

The discounting function $\Delta^*(a)$ is derived from allowing an evolutionary process to determine time preferences. The only assumption
we make is that the Lyapunov exponent, or monomorphic population growth rate, corresponds to evolutionary fitness. By studying
the functional form of the adaptive discounting function $\Delta^*(a)$, we infer that there are two distinct evolutionary pressures to prefer
immediate over delayed rewards. It is adaptive to prefer immediate rewards over delayed rewards due to both
risk of death and opportunity cost (that is, delayed rewards are intrinsically worth less). Our assumptions do not contradict those
of the exponential discounting model: while an environment may present constant risk, we allow individuals inside of that environment to experience
risk differently dependent on age. 

The mathematics in the previous section do not rely on the Lyapunov exponent $\lambda$ until it is used
explicitly to compute $\Delta^*(a)$. We could therefore
run through the same argument to produce a discounting function resulting from lifetime reproductive output $R_0$ as our measure of success. In this
case, 
\begin{equation}
    \Delta_{R_0}^*(a) = \prod\limits_{k = 0}^{a-1} s_k.
\end{equation}
Note that this is the same expression as when computing with the Lyapunov exponent with $\lambda = 1$. From this observation we derive insight into
the reason for the presence of each term in the adaptive discounting function $\Delta^*$. 
\begin{enumerate}
    \item The product $\prod s_k$ accounts for risk. Fecundity rewards later in life must be discounted since there is a risk that the
        agent not survive to benefit from them.
    \item The exponential term $\lambda^{-a}$ accounts for opportunity cost. When time preferences evolve in the context of a growing
        population, there is selective pressure to prefer more immediate rewards. 
\end{enumerate}

We see that populations which are of constant size see no opportunity cost to delaying
reproduction, whereas growing populations face more pressure to reproduce earlier. 
From an ecological perspective, therefore, our theoretical work provides quantitative justification for the phenomenological demographic principle that
``a slowly growing population selects a later age of first reproduction than does a rapidly growing population''  
\cite{bull04}.  

%\begin{table}[h]
%    \centering
%\begin{tabular}{|l|l|}
%    \hline
%Population Size & Opportunity Cost            \\ \hline \hline
%Constant             & None                            \\
%Growing         & Reproduce Earlier \\
%Shrinking       & Reproduce Later (Opportunity Benefit?) \\ \hline
%\end{tabular}
%\caption[Indicates opportunity cost as determined by demographic growth/decay.]{When a population is growing ($\lambda > 1$), there is an opportunity cost to reproducing later in life. Of note is that 
%when a population is dying out $(\lambda < 1)$, there is an opportunity benefit to delaying reproduction. If $\lambda < 1$, then in 
%the discounting function
%$\lambda^{-a}$ becomes larger as $a$ increases, so that an offspring produced late in life may be worth more than one produced earlier. If delayed
%rewards are valued more than earlier rewards (meaning the discounting function is increasing rather than decreasing), we 
%refer to such time preferences as inverted.}
%\end{table}

\section{Preference Reversals}
The time preferences described by the adaptive discounting function $\Delta^*(a)$ are compatible with preference reversals. 
So long as survival probability is not constant across age classes, $\Delta^*(a) \ne e^{-ra}$ for any $r$, which means discounting
is not exponential and preference reversals are guaranteed to occur. Therefore, our findings counter the common perception that preference
reversals are irrational, justifying them as an evolutionarily adaptive trait. 

If survival probability is of a very particular form, hyperbolic discounting is predicted. 
Suppose survival probability is given by $s_a = \frac{a+1}{a+2}$. If $\lambda$ is once more the Lyapunov exponent of the population, adaptive
discounting is given by the product $\Delta^*(a) = \lambda^{-a}\frac{1}{1+a}$, a combination of both exponential and hyperbolic discounting. 
If the population size is constant, then $\lambda = 1$ and time preferences are purely hyperbolic. More generally, if 
$h>0$ and $s_a = \frac{1+ha}{1 + h(a+1)}$, then adaptive discounting
is computed to be $\Delta^*(a) = \lambda^{-a}\frac{1}{1+ha}$. Facing a smaller/sooner versus larger/later dilemma, preference reversals are
predicted from smaller/sooner to larger/later as the delay to each alternative increases. 
More generally, preference reversals from $\smallersooner\to\largerlater$ are predicted to occur whenever survival probability is increasing in age:
$s_0 < s_1 < \ldots$.  On the other hand, if survival probability decreases in age ($s_0 > s_1 > \ldots$), preference reversals are 
predicted from $\largerlater\to\smallersooner$. 

Remark that the Lyapunov exponent $\lambda$ does not influence preference reversals. Since $\Delta^*(a) = \lambda^{-a} \prod s_k$, the Lyapunov
exponent appears as an exponential discounting factor and therefore implies no preference reversals. Only survival terms can yield  
time inconsistent preferences, or preference reversals. 

%preference reversals are predicted from $\smallersooner\to
%\largerlater$ as the age at dilemma increases.\begin{table}[h]
%    \centering
%\begin{tabular}{|l|l|}
%    \hline
%Survival Probability & Preference Reversals            \\ \hline \hline
%Constant             & None                            \\
%Increasing           & $\smallersooner\to\largerlater$ \\
%Decreasing           & $\largerlater\to\smallersooner$ \\ \hline
%\end{tabular}
%\caption[Association between survival probability and type of preference reversals.]{Survival probability 
%    determines whether preference reversals occur, and in which direction. Intuitively, if survival 
%decreases with age, then individuals are less willing to wait for delayed rewards later in life than they are early on. For instance,
%facing a smaller/sooner versus larger/later dilemma at age $25$, I may be willing to wait for the larger/later reward. At the age of
%$85$, however, the risk inherent in waiting means I prefer the smaller/sooner option.}
%\end{table}







\begin{figure}[H]
    \centering
    \includegraphics{stacked_life_histories.png}
    \caption[Life histories giving decaying, stable, and growing populations.]{Adaptive time preferences are determined (in part) by the baseline population growth rate $\lambda$. 
        We illustrate three life histories resulting in populations which are
        growing ($\lambda > 1$), stable ($\lambda = 1$), and decaying ($\lambda < 1$).}
\end{figure}
\newpage

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{growth_dependence.png}
    \includegraphics[scale = 0.8]{switching_point_growth.png}
    \caption[Appreciation and preference plots for different demographic trends.]{We compute adaptive time preferences for three basline life histories
    and represent each with an appreciation plot (a), (b), and (c) and a patience threshold (d). In all cases, survival probability is chosen to 
        produce hyperbolic discounting: $\Delta^*(a) = \lambda^{-a}\frac{1}{1+a}$. 
        In (a), if a population grows at rate $\lambda = 6/5$ per unit time, appreciation looks exponential.
        In (b), if $\lambda = 1$, the population is stable in size, and appreciation looks linear, indicative of hyperbolic discounting. Next, in
        (c),
        if the population decays at rate $\lambda = 5/6$, inverted time preferences are adaptive, meaning delayed rewards may be valued more than
        immediate alternatives. In plot (d) the same time preferences are represented as in (a), (b), and (c) using patience thresholds.
        The patience threshold is decreasing and the same shape for all values of $\lambda$. Preference reversals
    from smaller/sooner to larger/later are adaptive.}
\end{figure}
\newpage


\section{Application to Human Discounting}
Evolutionary life histories have been put forward for our own species, homo sapiens. By computing adaptive time preferences for homo spaiens' 
evolutionary life history, we may better understand empirically observed time preferences. By studying modern hunter/gatherer societies, Gurven and Kaplan 
estimate survival and fecundity schedules for humans prior to the introduction of modern medicine, diet, and lifestyle \cite{gurven07}. Specifically,
the authors approximate survival probability as 
\begin{equation}
    s_a = 1 - \alpha_1 e^{-\beta_1 a} + \alpha_2 + \alpha_3 e^{\beta_3 a}, 
    \label{eqn:siler}
\end{equation}
where $a$ is age measured in years. 

The survival function used accounts for elevated risk early in life, followed by a sustained
period of lower, constant risk, and finally steadily increasing risk late in life. By choosing the parameters $\alpha_j, \beta_k$ appropriately,
Gurven and Kaplan closely approximate the life histories of modern hunter/gatherer societies which we take as a proxy for human
evolutionary life history. From this life history, we derive time preferences from our adaptive discounting model. The life history 
derived from the Siler function gives time preferences which 
result in preference reversals early in life from $\smallersooner\to\largerlater$, and preference reversals later in life 
from $\largerlater\to\smallersooner$.
In between these two periods is a lengthy stretch during which discounting looks approximately exponential. 

\begin{figure}[h]
    \centering
    \includegraphics{evolved_preference_plot.png}
    \caption[Induced time preferences from an average evolutionary life history.]{A survival schedule  $(s_0, s_1, \ldots, s_{79})$
        has been estimated for homo sapiens prior to the introduction of modern medicine and lifestyle \cite{gurven07}. We leverage
        the survival function they provide for the Hadza hunter/gatherer society to compute the evolutionarily stable patience 
        threshold $(x_0^*, x_1^*, \ldots, x_{79}^*)$. Preference reversals are indicated by this patience threshold.  
        Early in life,
        preference reversals are predicted from smaller/sooner to larger/later. In mid-life, time preferences look approximately exponential. As death
        draws nearer in the final third of the life history, patience diminishes and preference reversals are predicted from larger/later 
        to smaller/sooner.}
\end{figure}





%\end{singlespace}


















\section{Conclusion}
In this paper we allow an evolutionary process to determine 
adaptive time preferences by performing an adaptive dynamics analysis. We use the Lyapunov exponent as 
a measure of evolutionary fitness and consequently find that time preferences are determined by risk and opportunity cost, the latter
measured by ambient population growth. Our findings show that time inconsistency in an evolutionarily adaptive trait, rather than an
irrationality. 

Our work may be seen as a starting point to understand the evolutionary dynamics of patience and time preferences rather
than a definitive conclusion. Our work may be extended by accounting for competition between individuals. For instance, perhaps
delayed rewards are less likely to be realized when an individual is surrounded by more hasty competitors. 
Preliminary exploration in this direction has found that competition induces less patience overall and still finds an evolutionarily stable
set of time preferences. An interesting result would be to model a scenario in which competition leads to evolutionary branching and the emergence
of diverse time preferences. 

Our work on determining adaptive discounting functions is a step toward the reconciliation of the theory and practice of time preferences. 
We have put forward a purely theoretical model capable of explaining the observed phenomena of hyperbolic discounting and preference
reversals. 
As
we discuss in the introduction, exponential discounting is rooted in mathematical models of behaviour, whereas hyperbolic discounting is supported
by empirical literature. We bridge the gap between the two perspectives by providing a fresh evolutionary angle. 





\newpage
\bibliographystyle{alpha}
\bibliography{research}{}


\end{document}

