\documentclass[titlepage, hidelinks, 12pt]{article}


%for custom page numbering:
\usepackage{fancyhdr}

\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{palatino}
\usepackage{tikz}
\usepackage{chngcntr}
\counterwithin{figure}{section}
%\usepackage{breqn} % useful for breaking equations across multiple lines automatically. Breaks everything.


\usepackage{setspace}
%\usepackage{indentfirst} %tex default is no indent on first paragraph after heading
\usepackage{url}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{float}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{environ, enumerate}
%\usepackage{mathbbol}
%\DeclareSymbolFontAlphabet{\amsmathbb}{AMSb}
\graphicspath{ {images/} }
\providecommand{\keywords}[1]{\textbf{\textit{Keywords---}} #1} 
\usepackage[format=plain,
            labelfont={bf, it},
            textfont=it]{caption}

\usepackage{lineno}

\usepackage{epigraph}

% \epigraphsize{\small}% Default
\setlength\epigraphwidth{8cm}
\setlength\epigraphrule{0pt}

\usepackage{etoolbox}

\makeatletter
\patchcmd{\epigraph}{\@epitext{#1}}{\itshape\@epitext{#1}}{}{}
\makeatother

% Align and Lineno do not play well together. This should fix it:

\newcommand*\linenomathpatch[1]{%
  \cspreto{#1}{\linenomath}%
  \cspreto{#1*}{\linenomath}%
  \csappto{end#1}{\endlinenomath}%
  \csappto{end#1*}{\endlinenomath}%
}

\linenomathpatch{equation}
\linenomathpatch{gather}
\linenomathpatch{multline}
\linenomathpatch{align}
\linenomathpatch{alignat}
\linenomathpatch{flalign}



%%%%%%%%%
% indentation
%%%%%%%%%

\setlength\parindent{24pt}

\setlength{\voffset}{-1cm}
\setlength{\textwidth}{17cm}
\addtolength{\textheight}{2cm}
\setlength{\footskip}{1cm}
\addtolength{\oddsidemargin}{-2cm}
\addtolength{\evensidemargin}{-2cm}

\widowpenalty10000
\clubpenalty10000

%%%%%%%%%
% page numbering and logo
%%%%%%%%%

\pagestyle{fancy}

\fancyhead[L, C]{}
\fancyhead[R]{\includegraphics[scale=.35]{sb_logo_black.png}}
\fancyfoot[L]{}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


%Def, Lemma, Theorem, Corollary environment
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{question}[theorem]{Question}
%\newtheorem*{proof}{Proof}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

%New commands
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\betahat}{\hat{\beta}}

\newcommand{\varSS}{\frac{\partial \lambda}{ \partial b_{a}}}
\newcommand{\varLL}{\frac{\partial \lambda}{ \partial b_{a+1}}}
\newcommand{\LH}{\mathcal{LH}}




%New math operators
\DeclareMathOperator{\ringchar}{char}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator*{\argmax}{argmax} \DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\MRS}{MRS}
\DeclareMathOperator{\smallersooner}{SS}
\DeclareMathOperator{\largerlater}{LL}
\DeclareMathOperator{\ES}{ES}
%\DeclareMathOperator{\exp}{exp}
\DeclareMathOperator{\hyp}{hyp}
\renewcommand\d[1]{\:\textrm{d}#1}
\newcommand*\diff{\mathop{\!\mathrm{d}}}

\doublespacing
\begin{document}
\begin{singlespace}
\begin{titlepage}
   \begin{center}
       \vspace*{1cm}
\Huge
       \textbf{The Adaptive Dynamics of Patience} \\
\Large
       \vspace{0.5cm}
      
            
       \vspace{4.1cm}
       \includegraphics[scale = 1.4]{sb_logo_black.png} \\
       \vspace*{\fill}
       \textbf{Eric, Christoph, and Jaye } 

            
       Department of Mathematics\\
       University of British Columbia
            
   \end{center}
\end{titlepage}


%%HERE IS A TEST CHANGE FOR BRANCH PURPOSES


\begin{abstract}
    Time preferences describe an individual's willingness to wait for a delayed reward in the presence of a smaller/sooner alternative. 
    Much debate has been had between the validity of the exponential and hyperbolic discounting models of time preferences on theoretical 
    and empirical grounds. 
We put forward an evolutionary model which allows adaptive pressures to mould time preferences. 
We consider a trait substitution sequence, which assumes a population with uniform time preferences subject to small, random mutations which
either fixate or are eliminated. We use
standard results from adaptive dynamics to explicitly compute an evolutionarily stable set of time preferences to which our trait substitution sequence
converges. Our results imply that individual survival probability and ambient population growth determine risk and opportunity cost, respectively.
    \bigskip

    \begin{keywords}
        Time Preferences, Adaptive Dynamics, Exponential Discounting, Life History, Preference Reversals. 
    \end{keywords}

\end{abstract}

%\newpage

%\tableofcontents

\newpage

%\section*{Acknowledgements}
%\addcontentsline{toc}{section}{Acknowledgement}
%\newpage
%\input{texfiles/outline}
%\newpage
\end{singlespace}

\epigraph{Time is the most valuable thing a man can spend.}{---Theophrastus}
\linenumbers
\section{Introduction}

Consider a choice between chocolate and fruit salad.
Chocolate promises immediate satisfaction, whereas fruit salad offers health benefits to be enjoyed later in time. 
When deciding between chocolate and fruit salad, an individual is weighing a small, immediate reward as compared with a larger,
more delayed alternative. 
For concreteness, suppose chocolate offers a reward of magnitude $1$ immediately, and fruit salad offers a benefit of $2$ after
a delay of $10$ units of time. 
Personal decisions involving delayed gratification include diet, exercise, and the management of addictions. 
More globally, government policies determine society's consumption level over time. 
Environmental policy, for instance,
dictates whether to reduce exploitation in the present to preserve resources for future use. 
This article explores how individuals weigh immediacy and magnitude to determine the value of a delayed reward. 

Time preferences describe how a decision maker's perceived value of a delayed reward changes as a function of the delay. 
A discounting function $\Delta$ quantitatively encodes time preferences: a reward received at delay $t\ge0$ maintains a fraction
$\Delta(t)$ of its value. Normally, $\Delta(0) = 1$ and $\Delta$ is decreasing in $t$. 
Returning to the original example, 
chocolate is preferred to fruit salad if and only if
\begin{align}
    \text{Benefit of Chocolate} &> (\text{Discount Factor}) \cdot (\text{Benefit of Fruit}) \\
    \iff 1 &> \Delta(10) \cdot 2.
    \label{eqn:choco_or_fruit}
\end{align}
Experimentalists and theorists take different approaches to derive discounting functions. Experimental studies collect data on
observed preferences and infer a discounting function by fitting a curve through data points. Theorists, on the other hand, axiomatise
rational behaviour and mathematically derive corresponding discounting functions \cite{mazur85, ainslie75, green81, green04}. 
Reconciling the theory and practice of time preferences is a central goal of this paper. 


If delayed rewards lose a constant fraction of their value for every unit-time delay, then discounting is exponential. 
For example, if fruit salad's delayed benefit loses a fraction $r\in(0, 1)$ for each unit of time $t$, then
fruit salad is discounted at a rate of 
\begin{align}
    \Delta_{\exp}(t) &= (1-r)^{t} \\
    &= e^{-\tilde r t} 
    \label{eqn:exponential_discounting}
\end{align}
for appropriate choice of $\tilde r$. 
The exponential discounting model is popular among economists in particular
for its straightforward assumptions and ease of use \cite{sozou98}. 
The exponential discounting model 
agrees with financial models in which loans accrue compound interest at a specified rate $r>0$. An initial loan of $P$ at compound interest
rate $r$ appreciates (after $t$ units of time) to 
\begin{equation}
    P(1 + r)^{t} = Pe^{\log(1+r) t} = Pe^{\tilde{r}t},
    \label{eqn:compound_interest}
\end{equation}
which grows (or appreciates) exponentially in time $t$. 



Some experimental results find that observed time preferences are better explained
by a hyperbolic, rather than exponential, discounting function \cite{maia09, green04, doyle12}. A hyperbolic discounting function takes
the form
\begin{equation}
    \Delta_{\hyp}(t) = \frac{1}{1+ht},
\end{equation}
where $h>0$ is a parameter analogous to $r$ in the exponential discounting model. The hyperbolic discounting model is considerably less
popular than the exponential model, in part due to its lack of theoretical foundations \cite{sozou98}. 
One derivation of the hyperbolic discounting model relies
on additive simple interest which in financial modelling is considered irrational \cite{rachlin06}. An initial loan
of $P$ at simple interest rate $h$ appreciates after $t$ units of time to
\begin{equation}
    P + hP + hP + \cdots + hP = P(1 + ht)
    \label{eqn:simple_interest}
\end{equation}
which appreciates linearly in time $t$. 
Consider briefly a deposit of \$1 in a bank account. The hyperbolic banker will receive the same interest per unit time. 
The exponential banker, on the other hand, receives ever increasing interest payments as compounding interest adds up. 
The supposed irrationality of hyperbolic discounting is due to the observation that the hyperbolic banker could withdraw and immediately
deposit their interest payments to earn additional interest. 


Discounting and appreciation equivalently define time preferences. The present value of fruit salad is given in Equation \ref{eqn:choco_or_fruit}.
The appreciated value of chocolate to time $t$ is 
\begin{equation}
    \frac{1}{\Delta(t)} \cdot \text{(Benefit of Chocolate)}. 
    \label{eqn:appreciation}
\end{equation}
Mathematically, appreciation and discounting are reciprocal. Discounting transforms the delayed reward to be comparable to present, whereas
appreciation transforms the immediate reward to be comparable to the future alternative. 
We use discounting or appreciation interchangeably given their dual nature. 

Experimentalists further find evidence of behaviour not compatible with the exponential discounting model \cite{read98}. 
The imposition of a common delay before the consumption of chocolate or fruit salad can significantly impacts preferences. 
Some study participants prefer chocolate if consumption is immediate and prefer fruit salad if consumption is after one week. 
To switch between impulsiveness (chocolate) and patience
(fruit) as
both alternatives become further removed is called a preference reversal. 
Notably, exponential discounting is the only model of time preferences which does not predict preference reversals
\cite{strotz55}. 




\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.4]{appreciated_and_discounted_fruit_and_chocolate.png}
    \caption[Graphical depiction of a preference reversal.]{A common delay of $t$ is experienced before consumption of both chocolate
    and fruit salad. Hyperbolic discounting results in a preference reversal: as the common delay increases past $t = 5$, the preferred
choice shifts from chocolate to fruit salad. Hyperbolic discounting is characterised by quasi-linear appreciation plots. Values $r = 1/20$ and
$h = 1/5$ used for demonstration purposes.} 
    \label{fig:discountedValueHyperbolic}
\end{figure}


We use techniques from evolutionary modeling to resolve the discrepency between the theory and the practice of time preferences.
While researchers, accountants, and financial engineers may quantify time preferences using
discounting functions, most smaller/sooner or larger/later decisions are guided by instinct rather than mathematics. 
The adaptive unconscious describes the collection of mental processes used when making 
decisions without conscious and deliberate consideration \cite{wegner02}. 
Our core assumption is that 
the adaptive unconscious determines time preferences, which in turn determine survival and reproduction likelihoods, 
which determine evolutionary fitness, which in turn feeds back into the adaptive unconscious. 
We use evolutionary modeling to determine the evolutionary dynamics of time preferences. 


Our research is not the first to focus on time preferences from an evolutionary angle. Previous approaches explicitly consider both
risk and opportunity cost to compute the relative value of immediate and delayed rewards, prescribing adaptive behaviour as a function of
each \cite{sozou98, fawcett12}. Risk describes the probability a delayed reward not be realized (due, for instance, to death
of the recipient); opportunity cost 
describes the lost potential of compounding gains due to delayed, rather than immediate, receipt of a reward. 
If risk is constant and known, 
adaptive time preferences are modeled by exponentially discounting delayed fitness gains; however, if risk is constant but drawn
from a probability distribution, non-exponential (and in particular, hyperbolic) discounting of delayed fitness gains may be adaptive \cite{sozou98}. 
If risk is constant, explicitly accounting for opportunity
cost to delayed fitness gains produces various models predicting preference reversals \cite{fawcett12}. 

Our approach differs from previous studies by considering dilemmas between delayed reproductive opportunities, rather than fitness gains. 
The mechanism mapping reproductive success to fitness therefore determines the relative value of rewards at different points in time. 
We derive an evolutionarily stable discounting function by applying adaptive dynamics to time preferences. 
Our evolutionarily stable discounting function naturally decomposes into risk and opportunity cost, factors which
must be assumed if discounting fitness gains directly. 

Some highlights from this approach:
\begin{itemize}
    \item Exponential discounting might be rational.
    \item Non-constant survival probability results in non-exponential time preferences. In particular, preference reversals
        abound.
    \item Time preferences determined by adaptive dynamics might result in upward sloping discounting functions. An offspring later in life could
        be preferred to an offspring earlier, even in the absence of any parental care. 
\end{itemize}




\section{Life Histories and Reproductive Success}

To model the evolution of time preferences, consider a population with discrete age classes $a\in\left\{ 0, 1, \ldots, A \right\}$. 
Assuming discrete age classes is not limiting since we may take units of time small enough so as to approximate continuous time. Further,
the maximal age $A$ may be justified by choosing $A$ large enough so that the probability of surviving to to age $A$ is negligible. Survival
and reproduction are uniform across the population: each individual produces on average $b_a$ offspring at age $a$, and survives from $a$
to $a+1$ with with probability $s_a$. The survival and reproduction schedule $(\vec{s}, \vec{b}) = (s_0, s_1, \ldots, s_{A-1}, s_A = 0), (b_0, b_1, 
\ldots, b_A)$ is called the baseline life history $\LH_0$. 


In our model, agents face reproductive dilemmas: 
a choice between some offspring early in life and more offspring later. 
While all individuals share the same baseline life history $\LH_0$, their time preferences may vary so that reproductive schedules differ
slightly. Time preferences can mutate beteween generations, and therefore
evolutionary dynamics determine time preferences. 
Fitness is required to model the evolutionary dynamics of time preferences, so to 
compute the relative fitness benefit of
additional offpsring at different ages, we introduce two 
measures from evolutionary ecology: lifetime reproductive output $R_0$ and monomorphic population growth rate $\lambda$ 
\cite{stearns92}.



Lifetime reproductive output is computed as
\begin{equation}
    R_0 = \sum\limits_{a = 0}^A \prod\limits_{k = 0}^{a-1} s_k b_a.
    \label{eqn:output}
\end{equation}
Equation \ref{eqn:output} is the sum of the expected number of offspring produced at each age $a= 0, 1, \ldots, A$; here,
and throughout, the empty product evaluates to 1. 
Population growth (also called the Lyapunov exponent) $\lambda$
appears in the discrete-time Euler-Lotka equation,
\begin{equation}
    \lambda^{A+1} - \sum\limits_{a = 0}^A \lambda^{A-a} \prod\limits_{k = 0}^{a-1}s_k b_k= 0.
    \label{eqn:euler-lotka}
\end{equation}


Whereas the expression for $R_0$ is easily computed, the Euler-Lotka equation
is a polynomial in $\lambda$ of degree $A+1$, and so has up to $A+1$ distinct solutions. The largest of these solutions is the growth
rate of a monomorphic population, the Lyapunov exponent.
The Euler-Lotka equation is derived from the Leslie matrix describing population dynamics with life history $\LH_0$ \cite{stearns92}.
While it is not possible to compute analytically, the Lyapunov exponent is implicitly a function of life history data:
\begin{equation}
    \lambda = \lambda(\LH_0) = \lambda(s_0, s_1, \ldots, s_{A-1}, b_0, b_1, \ldots, b_{A}).
    \label{eqn:lambda_function}
\end{equation}
In practice, the Lyapunov exponent is computed numerically. 
In the long run, a population with fixed life history will converge to a stable age distribution and
thus grow (or decay) 
exponentially at a constant rate $\lambda$ per unit time. If $\lambda = 1$, then the population remains at a fixed size indefinitely.

The fitness measures $R_0$ and $\lambda$ evaluate the relative value of offspring differently. Specifically, lifetime reproductive 
output $R_0$ does not account for compounding benefits from early reproduction. Absent risk, offspring at age $0$ contribute equally to
$R_0$ as offspring at maximum age $A$. Monomorphic growth rate $\lambda$, then, accounts for opportunity cost which $R_0$ neglects. 
We therefore favour population growth $\lambda$ as our measure of reproductive success. The assumption that populations grow exponentially is limiting: if
ever $\lambda > 1$,  the implicit assumption is that resources are in inexhaustible supply 
and do not constrain growth. A sustainable population is one that is of constant size, which has
$\lambda \approx 1$. If two phenotypes with different Lyapunov exponents compete, the one with the larger $\lambda$ value dominates.
The question is now: If selective pressures form time preferences to maximize $\lambda$, what form does the resulting discounting function take?


\section{Reproductive Dilemmas}
A variable environment presents individuals with fecundity dilemmas, meaning a decision must be made between some offspring
immediately and more offspring later in life. More technically, let $\varepsilon > 0$ be small. A fecundity dilemmas is a choice
between the smaller/sooner option of increasing $b_a$ to $b_a + \varepsilon$, and the larger/later option of increasing $b_{a+1}$ to
$b_{a+1} + F\cdot \varepsilon$. That $\varepsilon$ is small encodes the assumption that environmental variability changes reproductive
probabilities only slightly. 


Denote each dilemma by the pair $(a, F)$, where $a$ is the age at which the dilemma is faced,
and $F$ is the ratio of $\largerlater$ to $\smallersooner$. 
Remark that we assume dilemmas are between age $a$ and $a+1$ rather than an arbitrary delay $a+t$. This restriction simplifies our analysis
while still allowing for a full understanding of evolved time preferences, since knowing preferences between $a$ and $a+1$ as well as between
$a+1$ and $a+2$, we infer preferences between $a$ and $a+2$. 

\begin{figure}[H]
    \centering
    \includegraphics{evolutionary_dilemma.png}
    \caption[Baseline life history and reproductive dilemma example.]{A baseline life history $\vec{s}, \vec{b}$ can be visualized as a bar plot. The bar at $a$ is the expected number of offspring at
        age $a$, given by
    $\prod_{k = 0}^{a-1} s_k b_a$. Reproductive dilemmas are additions to fecundity. Illustrated is the dilemma $(2, 3)$, with
$\varepsilon = 0.01$. That is, an agent faces a choice between an additional $0.01$ offspring at age $2$ and an additional $0.03$ offspring
at age $3$.} 
\end{figure}

Individuals in our model have time preferences which indicate their preferred choice between $\smallersooner$ and $\largerlater$ facing any
dilemma. 
Consider a dilemma $(a, F)$. The switching point $x_a$ is the unique value satisfying that $\smallersooner$ is preferred
if and only if $F < x_a$. 
A patience threshold is a collection of switching points $(x_0, \ldots, x_{A-1})$.
Since a patience threshold indicates preferences facing any dilemma $(a, F)$, time preferences may be uniquely 
specified by either a patience threshold or a discounting function. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{switching_point_pref_rev.png}
    \caption[Patience threshold and alternative perspective on preference reversals.]{Patience thresholds are mathematically convenient and provide a straightforward visual representation of time preferences. 
        Every point in $(a, F)$ space
    represents a dilemma at age $a$ with reward ratio $\largerlater : \smallersooner = F$. 
    Those points above the patience threshold correspond to dilemmas at which the $\largerlater$ alternative
is preferred. Those points below the threshold are when $\smallersooner$ is preferred. The patience threshold also allows
illustrates preference reversals. Consider the family of dilemmas $(a, 1.5)$, with age at dilemma $a$ variable (dotted black line). If the dilemma comes 
before age $a = 1$, the agent 
prefers $\smallersooner$. However, if the dilemma comes later in life, then $\largerlater$ is preferred. More generally, a
downward sloping patience threshold indicates preference reversals from $\smallersooner\to\largerlater$, and an upward sloping threshold
indicates the reverse. A horizontal patience threshold is consistent with exponential discounting, and indicates no preference reversals.
}
\end{figure}

By way of summary, our model includes a large (or infinite) population sharing the same baseline life history $\LH_0 = (\vec{s}, \vec{b}).$ 
Each agent faces a stochastically determined dilemma, denoted $(a, F)$, between a smaller/sooner and a larger/later fecundity reward. 
Time preferences are given by a patience threshold $(x_0, x_1, \ldots, x_{A-1})$. 
An individual's time preferences determine their reproductive success; by using the Lyapunov exponent $\lambda$ to measure reproductive 
success, we are using the difference in population growth rate between residents and mutants to compute the evolutionary dynamics of time
preferences and patience. 


\section{Adaptive Dynamics of Patience}
Adaptive dynamics is a framework for mathematically describing the trajectory of a continuosly varying trait when subject to evolutionary pressures. 
Adaptive dynamics makes two key assumptions. We assume that mutations (i) are small, and (ii) occur infrequently.
Under these assumptions, a mutant either goes extinct or replaces the resident population before any more mutations occur \cite{doebeli05}.
A value to which a trait converges is called convergent stable. A value to which a trait remains if already there is called evolutionarily stable.
Neither form of stability implies the other. For instance, a trait value which is convergent stable and not evolutionarily stable is called an
evolutionary branching point. A major contribution of adaptive dynamics is the explanation of sympatric speciation, the 
evolution of two different species in the same environment \cite{doebeli11}. 

More technincally, suppose a continuously varying trait is subject to evolutionary pressures. \textit{Invasion fitness} is the relative
success of a rare mutant with trait value $y$ invading into a monomorphic population with trait value $x$, $\varphi(y, x)$. If invasion
fitness is positive, $\varphi(y, x) > 0$, then a rare mutant fixates. Our framework lends itself well to analysis by differentiation. 
Increasing the trait value slightly is either beneficial, in which case the mutation fixates, or it is not beneficial, in which
case the mutation vanishes. Adaptive dynamics describes the trajectory of the trait value $x$. 
The \textit{selection gradient} is the function 
\begin{equation}
    D(x) = \left.\frac{\partial }{\partial y} \right\vert_{y = x}\varphi(y, x).
    \label{eqn:selection_gradient}
\end{equation}
If trait value $x$ is such that $D(x) > 0$, increasing the trait value is adaptive. If $x^*$ is such that $D(x^*) = 0$, then $x^*$ is a
singular value. If $D(x^*) = 0$ and $D'(x^*) < 0$, 
then $x^*$ is convergent stable: the trait value will converge to $x^*$. To determine if the trait value will remain at $x^*$, compute
\begin{equation}
    \ES(x) = \left.\frac{\partial^2 }{\partial y^2} \right\vert_{y = x}\varphi(y, x).
    \label{eqn:evolutionary_stability}
\end{equation}
If $\ES(x^*) < 0$, then trait value $x^*$ is evolutionarily stable. The trait converges to and remains at $x^*$. On the other hand, if
$\ES(x^*) > 0$, then $x^*$ is an evolutionary branching point: after converging to $x^*$, two distinct populations diverge from value $x^*$, one
with trait values above and the other below $x^*$.  We here apply adaptive dynamics to the evolution of time preferences. 

Suppose a population has baseline life history $\LH_0$ and begins with all individuals having the same time preferences,
encoded as a patience threshold $(x_0, x_1, \ldots, x_{A-1})$. We compute the adaptive dynamics of each switching point
$x_a$ independently. We first consider a mutant with switching point $y_a > x_a$ for age at dilemma $a$ fixed. 
The mutant under consideration is slightly less patient than the resident population. Residents and mutants obtain identical outcomes except for dilemmas
at age $a$ with ratio $F$ such that $x_a < F < y_a$, meaning residents choose $\largerlater$ and mutants choose $\smallersooner$. 
To determine if the mutant with trait value $y_a$ is benefited, we analytically compute reproductive success via a first order Taylor approximation:
\begin{align}
    \lambda(\LH_0 + \smallersooner) &\approx \lambda(\LH_0) + \varepsilon \cdot \varSS \\
    \lambda(\LH_0 + \largerlater) &\approx \lambda(\LH_0) + F\varepsilon \cdot \varLL.
\end{align}
Recall from equation (\ref{eqn:lambda_function}) that the Lyapunov exponent is implicitly a function of the fecundity terms $b_a$. 
From the Taylor approximation we identify the payoff from choosing each alternative, 
$\pi_{\smallersooner}$ and $\pi_{\largerlater}(F)$. Remark that the larger/later payout
varies as a function of $F$, whereas the smaller/sooner payout is constant. We have: 
\begin{align}
    \pi_{\smallersooner} &= \varepsilon\cdot \varSS \label{eqn:varss} \\ 
    \pi_{\largerlater}(F) &= F\varepsilon\cdot \varLL. \label{eqn:varll}
\end{align}

Invasion fitness describes the relative success of a rare mutant, and is the difference in reproductive success between
a mutant and residents.  We assume dilemmas
vary stochastically, so invasion fitness is the \textit{average} difference in success. Suppose the larger/later value $F$ is distributed with probability
density function $g(F)$. 
Denote by $\varphi_a(y_a, x_a)$ the invasion fitness of a mutant with switching point
$y_a$ into a resident population with switching point $x_a$.  
Recall that when $x_a < F < y_a$, residents choose the larger/later option and mutants prefer the smaller/sooner alternative, whereas
outside of this interval outcomes are identical. Invasion fitness is then the average difference $\pi_{\smallersooner} - \pi_{\largerlater}(F)$
over all dilemmas $(a, F)$, for $a$ fixed. 
Mathematically, therefore, invasion fitness is given by 
\begin{align}
    \varphi_a(y_a, x_a) &= \mathbb{E}\left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \ | \ x_a < F < y_a\right] \\
    &= \int_{x_a}^{y_a} \left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \right]g(F) \d F. 
\end{align}
Remark that the expression for invasion fitness
$\varphi_a$ is the same whether $x_a < y_a$ or $y_a < x_a$, and is $0$ when $x_a = y_a$. 
Since we assume dilemmas are distributed randomly, we compute the expected value as a weighted integral according to the distribution of $F$ over
the interval on which the payouts differ. 

From invasion fitness $\varphi_a(y_a, x_a)$, we compute the selection gradient $D(x_a)$ to determine which switching points
are singular strategies.  
Recall that increasing the switching point $x_a$ is adaptive if and only if $D(x_a) > 0$. We compute: 
\begin{align}
    D(x_a) &= \left.\frac{\partial }{\partial y_a} \right\vert_{y_a = x_a}\varphi_a(y_a, x_a)  \\
    &=\left.\frac{\partial }{\partial y_a} \right\vert_{y_a = x_a}  \int_{x_a}^{y_a} \left[ \pi_{\smallersooner} - \pi_{\largerlater}(F) \right]g(F) \d F\\
        &=\left[ \pi_{\smallersooner} - \pi_{\largerlater}(x_a)   \right]g(x_a) 
\end{align}
We verify that $D(x_a^*) = 0$ is solved whenever the payout from choosing smaller/sooner equals that from choosing larger/later,
$\pi_{\smallersooner} = \pi_{\largerlater}(x_a^*)$. Intuitively, this result is reasonable: the singular switching point 
is the one at which the payout from smaller/sooner is the same as that from larger/later. 
We compute from equations (\ref{eqn:varss}) and (\ref{eqn:varll}) that
$x_a^* =  \varSS/\varLL$. 

We can further show that $x_a^*$ 
is both convergent stable and evolutionarily stable. Convergent stability follows from showing that $D'(x_a^*) < 0$, whereas evolutionary
stability follows from showing that $\frac{\partial^2 \varphi_a}{\partial y_a^2}(x_a^*, x_a^*)< 0$. In our case, the conditions are equivalent,
so we compute:
\begin{align}
    \frac{\partial^2 \varphi_a}{\partial y_a^2}(y_a, x_a) &=\frac{\partial}{\partial y_a}\left[\varSS \cdot \varepsilon  - \varLL \cdot y_a\varepsilon \right] g(y_a)\\
    &= \left[ -\varepsilon \varLL \right]\cdot g(y_a) + \left[ \varepsilon \varSS - y_a \right]
\end{align}
By evaluating at $(y_a, x_a) = (x_a^*, x_a^*)$, we determine the convergent and evolutionary stability of $x_a^*$. 
\begin{align}
    \frac{\partial^2 \varphi_a}{\partial y^2}(x_a^*, x_a^*) &= -\varepsilon \varLL g(x_a^*) + \left[ \varepsilon \varSS - \varepsilon \frac{\varSS}{\varLL}
    \varLL\right]g'(x_a^*) \\
    &= -\varepsilon \varLL g(x_a^*) + \left[0  \right]\cdot g'(x_a^*)\\
    &= -\varepsilon\varLL g(x_a^*) < 0 \label{eqn:negative}
\end{align}
The quantity in line (\ref{eqn:negative}) is negative. By assumption, $\varepsilon > 0$. Since $g$ is a probability density function, it is also
positive. Finally, since reproductive success $\lambda$ increases with fecundity, the derivative is also positive, and so the expression is
negative. 
We conclude that the switching point will converge to $x_a^*$, and once there, it will not deviate: the switching point $x_a^*$ is both
convergent and evolutionarily stable. 

Remark that the switching point $x_a^* =  \varSS/\varLL$ has been computed specifically for dilemmas at age $a$. We therefore now extend to
the evolutionarily stable patience threshold $(x_0^*, x_1^*, \ldots, x_{A-1}^*)$. 
We may translate with ease between discounting functions and patience thresholds. Given any patience threshold $(x_0, x_1, \ldots)$, the corresponding
discounting schedule is given by 
\begin{equation}
    \Delta(t) = \left( \prod\limits_{k = 0}^{t - 1} x_k \right)^{-1}. \label{eqn:disc_from_thresh}
\end{equation}
Consequently, the evolutionarily stable discounting function (corresponding to our derived patience threshold) is
\begin{equation}
    \Delta^*(a) = \varSS/\frac{\partial \lambda}{\partial b_0}. 
    \label{eqn:stable_discounting}
\end{equation}
Between equations (\ref{eqn:disc_from_thresh}) and (\ref{eqn:stable_discounting}), the delay variable changes from $t$ to $a$. 
We do so to highlight an important difference between the classical theory of time preferences and our approach. 
Classical discounting functions are age agnostic: delayed rewards are discounted to present value. In our evolutionarily stable discounting
function $\Delta^*(a)$, however, age matters. Rather than offering a reward today or more tomorrow, we offer a reward at age $a$ or a larger
reward at age $a+1$. To compare delayed rewards against a common benchmark, delayed rewards are translated to discounted value at
age $0$, the initial age class. 

The Euler-Lotka equation can be leveraged to compute an expression for the evolutionarily stable switching points. By using
implicit differentiation, we compute
\begin{equation}
    \frac{\partial \lambda}{\partial b_a} = K\cdot \lambda^{-a} \prod\limits_{k = 0}^{a-1}s_k,
\end{equation}
where $K>0$ is an expression independent of $a$. We can now compute the evolutionarily stable switching point 
\begin{equation}
    x_a^* = \frac{\varSS}{\varLL} = \frac{K\cdot \lambda^{-a} \prod\limits_{k = 0}^{a-1}s_k}{K\cdot \lambda^{-a-1} \prod\limits_{k = 0}^{a}s_k} = \frac{\lambda}{s_a}.
\end{equation}
We further compute the adaptive discounting function
\begin{equation}
    \Delta^*(a) = \lambda^{-a}\prod\limits_{k = 0}^{a-1} s_k.
\end{equation}



\section{Interpretation and Discussion}

The discounting function $\Delta^*(a)$ is derived from allowing an evolutionary process to determine time preferences. The only assumption
we make is that the Lyapunov exponent, or monomorphic population growth rate, corresponds to evolutionary fitness. By studying
the functional form of the adaptive discounting function $\Delta^*(a)$, we infer that there are two distinct evolutionary pressures to prefer
immediate over delayed rewards. It is adaptive to prefer immediate rewards over delayed rewards due to both
risk of death and opportunity cost (that is, delayed rewards are intrinsically worth less). Our assumptions do not contradict those
of the exponential discounting model: while an environment may present constant risk, we allow individuals inside of that environment to experience
risk differently dependent on age. 

The mathematics in the previous section do not rely on the Lyapunov exponent $\lambda$ until it is used
explicitly to compute $\Delta^*(a)$. We could therefore
run through the same argument to produce a discounting function resulting from lifetime reproductive output $R_0$ as our measure of success. In this
case, 
\begin{equation}
    \Delta_{R_0}^*(a) = \prod\limits_{k = 0}^{a-1} s_k.
\end{equation}
Note that this is the same expression as when computing with the Lyapunov exponent with $\lambda = 1$. From this observation we derive insight into
the reason for the presence of each term in the adaptive discounting function $\Delta^*$. 
\begin{enumerate}
    \item The product $\prod s_k$ accounts for risk. Fecundity rewards later in life must be discounted since there is a risk that the
        agent not survive to benefit from them.
    \item The exponential term $\lambda^{-a}$ accounts for opportunity cost. When time preferences evolve in the context of a growing
        population, there is selective pressure to prefer more immediate rewards. 
\end{enumerate}

We see that populations which are of constant size see no opportunity cost to delaying
reproduction, whereas growing populations face more pressure to reproduce earlier. 
From an ecological perspective, therefore, our theoretical work provides quantitative justification for the phenomenological demographic principle that
``a slowly growing population selects a later age of first reproduction than does a rapidly growing population''  
\cite{bull04}.  

%\begin{table}[h]
%    \centering
%\begin{tabular}{|l|l|}
%    \hline
%Population Size & Opportunity Cost            \\ \hline \hline
%Constant             & None                            \\
%Growing         & Reproduce Earlier \\
%Shrinking       & Reproduce Later (Opportunity Benefit?) \\ \hline
%\end{tabular}
%\caption[Indicates opportunity cost as determined by demographic growth/decay.]{When a population is growing ($\lambda > 1$), there is an opportunity cost to reproducing later in life. Of note is that 
%when a population is dying out $(\lambda < 1)$, there is an opportunity benefit to delaying reproduction. If $\lambda < 1$, then in 
%the discounting function
%$\lambda^{-a}$ becomes larger as $a$ increases, so that an offspring produced late in life may be worth more than one produced earlier. If delayed
%rewards are valued more than earlier rewards (meaning the discounting function is increasing rather than decreasing), we 
%refer to such time preferences as inverted.}
%\end{table}

\section{Preference Reversals}
The time preferences described by the adaptive discounting function $\Delta^*(a)$ are compatible with preference reversals. 
So long as survival probability is not constant across age classes, $\Delta^*(a) \ne e^{-ra}$ for any $r$, which means discounting
is not exponential and preference reversals are guaranteed to occur. Therefore, our findings counter the common perception that preference
reversals are irrational, justifying them as an evolutionarily adaptive trait. 

If survival probability is of a very particular form, hyperbolic discounting is predicted. 
Suppose survival probability is given by $s_a = \frac{a+1}{a+2}$. If $\lambda$ is once more the Lyapunov exponent of the population, adaptive
discounting is given by the product $\Delta^*(a) = \lambda^{-a}\frac{1}{1+a}$, a combination of both exponential and hyperbolic discounting. 
If the population size is constant, then $\lambda = 1$ and time preferences are purely hyperbolic. More generally, if 
$h>0$ and $s_a = \frac{1+ha}{1 + h(a+1)}$, then adaptive discounting
is computed to be $\Delta^*(a) = \lambda^{-a}\frac{1}{1+ha}$. Facing a smaller/sooner versus larger/later dilemma, preference reversals are
predicted from smaller/sooner to larger/later as the delay to each alternative increases. 
More generally, preference reversals from $\smallersooner\to\largerlater$ are predicted to occur whenever survival probability is increasing in age:
$s_0 < s_1 < \ldots$.  On the other hand, if survival probability decreases in age ($s_0 > s_1 > \ldots$), preference reversals are 
predicted from $\largerlater\to\smallersooner$. 

Remark that the Lyapunov exponent $\lambda$ does not influence preference reversals. Since $\Delta^*(a) = \lambda^{-a} \prod s_k$, the Lyapunov
exponent appears as an exponential discounting factor and therefore implies no preference reversals. Only survival terms can yield  
time inconsistent preferences, or preference reversals. 

%preference reversals are predicted from $\smallersooner\to
%\largerlater$ as the age at dilemma increases.\begin{table}[h]
%    \centering
%\begin{tabular}{|l|l|}
%    \hline
%Survival Probability & Preference Reversals            \\ \hline \hline
%Constant             & None                            \\
%Increasing           & $\smallersooner\to\largerlater$ \\
%Decreasing           & $\largerlater\to\smallersooner$ \\ \hline
%\end{tabular}
%\caption[Association between survival probability and type of preference reversals.]{Survival probability 
%    determines whether preference reversals occur, and in which direction. Intuitively, if survival 
%decreases with age, then individuals are less willing to wait for delayed rewards later in life than they are early on. For instance,
%facing a smaller/sooner versus larger/later dilemma at age $25$, I may be willing to wait for the larger/later reward. At the age of
%$85$, however, the risk inherent in waiting means I prefer the smaller/sooner option.}
%\end{table}







\begin{figure}[H]
    \centering
    \includegraphics{stacked_life_histories.png}
    \caption[Life histories giving decaying, stable, and growing populations.]{Adaptive time preferences are determined (in part) by the baseline population growth rate $\lambda$. 
        We illustrate three life histories resulting in populations which are
        growing ($\lambda > 1$), stable ($\lambda = 1$), and decaying ($\lambda < 1$).}
\end{figure}
\newpage

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.8]{growth_dependence.png}
    \includegraphics[scale = 0.8]{switching_point_growth.png}
    \caption[Appreciation and preference plots for different demographic trends.]{We compute adaptive time preferences for three basline life histories
    and represent each with an appreciation plot (a), (b), and (c) and a patience threshold (d). In all cases, survival probability is chosen to 
        produce hyperbolic discounting: $\Delta^*(a) = \lambda^{-a}\frac{1}{1+a}$. 
        In (a), if a population grows at rate $\lambda = 6/5$ per unit time, appreciation looks exponential.
        In (b), if $\lambda = 1$, the population is stable in size, and appreciation looks linear, indicative of hyperbolic discounting. Next, in
        (c),
        if the population decays at rate $\lambda = 5/6$, inverted time preferences are adaptive, meaning delayed rewards may be valued more than
        immediate alternatives. In plot (d) the same time preferences are represented as in (a), (b), and (c) using patience thresholds.
        The patience threshold is decreasing and the same shape for all values of $\lambda$. Preference reversals
    from smaller/sooner to larger/later are adaptive.}
\end{figure}
\newpage


\section{Application to Human Discounting}
Evolutionary life histories have been put forward for our own species, homo sapiens. By computing adaptive time preferences for homo spaiens' 
evolutionary life history, we may better understand empirically observed time preferences. By studying modern hunter/gatherer societies, Gurven and Kaplan 
estimate survival and fecundity schedules for humans prior to the introduction of modern medicine, diet, and lifestyle \cite{gurven07}. Specifically,
the authors approximate survival probability as 
\begin{equation}
    s_a = 1 - \alpha_1 e^{-\beta_1 a} + \alpha_2 + \alpha_3 e^{\beta_3 a}, 
    \label{eqn:siler}
\end{equation}
where $a$ is age measured in years. 

The survival function used accounts for elevated risk early in life, followed by a sustained
period of lower, constant risk, and finally steadily increasing risk late in life. By choosing the parameters $\alpha_j, \beta_k$ appropriately,
Gurven and Kaplan closely approximate the life histories of modern hunter/gatherer societies which we take as a proxy for human
evolutionary life history. From this life history, we derive time preferences from our adaptive discounting model. The life history 
derived from the Siler function gives time preferences which 
result in preference reversals early in life from $\smallersooner\to\largerlater$, and preference reversals later in life 
from $\largerlater\to\smallersooner$.
In between these two periods is a lengthy stretch during which discounting looks approximately exponential. 

\begin{figure}[h]
    \centering
    \includegraphics{evolved_preference_plot.png}
    \caption[Induced time preferences from an average evolutionary life history.]{A survival schedule  $(s_0, s_1, \ldots, s_{79})$
        has been estimated for homo sapiens prior to the introduction of modern medicine and lifestyle \cite{gurven07}. We leverage
        the survival function they provide for the Hadza hunter/gatherer society to compute the evolutionarily stable patience 
        threshold $(x_0^*, x_1^*, \ldots, x_{79}^*)$. Preference reversals are indicated by this patience threshold.  
        Early in life,
        preference reversals are predicted from smaller/sooner to larger/later. In mid-life, time preferences look approximately exponential. As death
        draws nearer in the final third of the life history, patience diminishes and preference reversals are predicted from larger/later 
        to smaller/sooner.}
\end{figure}





%\end{singlespace}


















\section{Conclusion}
In this paper we allow an evolutionary process to determine 
adaptive time preferences by performing an adaptive dynamics analysis. We use the Lyapunov exponent as 
a measure of evolutionary fitness and consequently find that time preferences are determined by risk and opportunity cost, the latter
measured by ambient population growth. Our findings show that time inconsistency in an evolutionarily adaptive trait, rather than an
irrationality. 

Our work may be seen as a starting point to understand the evolutionary dynamics of patience and time preferences rather
than a definitive conclusion. Our work may be extended by accounting for competition between individuals. For instance, perhaps
delayed rewards are less likely to be realized when an individual is surrounded by more hasty competitors. 
Preliminary exploration in this direction has found that competition induces less patience overall and still finds an evolutionarily stable
set of time preferences. An interesting result would be to model a scenario in which competition leads to evolutionary branching and the emergence
of diverse time preferences. 

Our work on determining adaptive discounting functions is a step toward the reconciliation of the theory and practice of time preferences. 
We have put forward a purely theoretical model capable of explaining the observed phenomena of hyperbolic discounting and preference
reversals. 
As
we discuss in the introduction, exponential discounting is rooted in mathematical models of behaviour, whereas hyperbolic discounting is supported
by empirical literature. We bridge the gap between the two perspectives by providing a fresh evolutionary angle. 





\newpage
\bibliographystyle{alpha}
\bibliography{research}{}


\end{document}

